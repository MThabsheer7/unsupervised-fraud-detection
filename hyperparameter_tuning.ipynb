{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f00cffc",
   "metadata": {},
   "source": [
    "- The model is performing at a low recall (28.25%)\n",
    "- When we set contamination to percentage value of frauds present in the actual dataset, we the same percentage of perdictions classified as fraud (anomalies).\n",
    "- Goal here is to explore how changing the contamination parameter affects the trade-off between identifying more actual frauds (recall) and reducing false alarms (precision).\n",
    "- In a real world scenario, where we dont know the exact fraud rate, we would experiment this parameter.\n",
    "- The tradeoff is between precision and recall.\n",
    "    - If we go for higher values of contamination, more samples get classified as frauds, increasing the recall. But at the same time, the precision would go down, i.e more false positives.\n",
    "    - The other way, if we go for lower contamination, less samples get classified as frauds, increasing the precision. But we will miss many actual fraud cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f029698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\".\\data\\creditcard.csv\")\n",
    "X = pd.read_csv(r\".\\preprocessed_data.csv\")\n",
    "y_true = pd.read_csv(r\".\\data\\y_true.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e27689f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Isolation Forest with contamination = 0.0017\n",
      "Classification Report for contamination=0.0017:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       1.00      1.00      1.00    284315\n",
      "       Fraud       0.28      0.28      0.28       492\n",
      "\n",
      "    accuracy                           1.00    284807\n",
      "   macro avg       0.64      0.64      0.64    284807\n",
      "weighted avg       1.00      1.00      1.00    284807\n",
      "\n",
      "Confusion Matrix:\n",
      "[[283962    353]\n",
      " [   353    139]]\n",
      "\n",
      "Testing Isolation Forest with contamination = 0.0010\n",
      "Classification Report for contamination=0.0010:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       1.00      1.00      1.00    284315\n",
      "       Fraud       0.37      0.21      0.27       492\n",
      "\n",
      "    accuracy                           1.00    284807\n",
      "   macro avg       0.68      0.61      0.63    284807\n",
      "weighted avg       1.00      1.00      1.00    284807\n",
      "\n",
      "Confusion Matrix:\n",
      "[[284135    180]\n",
      " [   387    105]]\n",
      "\n",
      "Testing Isolation Forest with contamination = 0.0020\n",
      "Classification Report for contamination=0.0020:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       1.00      1.00      1.00    284315\n",
      "       Fraud       0.26      0.30      0.27       492\n",
      "\n",
      "    accuracy                           1.00    284807\n",
      "   macro avg       0.63      0.65      0.64    284807\n",
      "weighted avg       1.00      1.00      1.00    284807\n",
      "\n",
      "Confusion Matrix:\n",
      "[[283891    424]\n",
      " [   346    146]]\n",
      "\n",
      "Testing Isolation Forest with contamination = 0.0050\n",
      "Classification Report for contamination=0.0050:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       1.00      1.00      1.00    284315\n",
      "       Fraud       0.16      0.47      0.24       492\n",
      "\n",
      "    accuracy                           0.99    284807\n",
      "   macro avg       0.58      0.73      0.62    284807\n",
      "weighted avg       1.00      0.99      1.00    284807\n",
      "\n",
      "Confusion Matrix:\n",
      "[[283120   1195]\n",
      " [   263    229]]\n",
      "\n",
      "--- Contamination Experimentation Summary ---\n",
      "Contamination_0.0017:\n",
      "  Precision_Fraud: 0.2825\n",
      "  Recall_Fraud: 0.2825\n",
      "  F1_Fraud: 0.2825\n",
      "  Num_Predicted_Anomalies: 492.0000\n",
      "Contamination_0.0010:\n",
      "  Precision_Fraud: 0.3684\n",
      "  Recall_Fraud: 0.2134\n",
      "  F1_Fraud: 0.2703\n",
      "  Num_Predicted_Anomalies: 285.0000\n",
      "Contamination_0.0020:\n",
      "  Precision_Fraud: 0.2561\n",
      "  Recall_Fraud: 0.2967\n",
      "  F1_Fraud: 0.2750\n",
      "  Num_Predicted_Anomalies: 570.0000\n",
      "Contamination_0.0050:\n",
      "  Precision_Fraud: 0.1608\n",
      "  Recall_Fraud: 0.4654\n",
      "  F1_Fraud: 0.2390\n",
      "  Num_Predicted_Anomalies: 1424.0000\n",
      "\n",
      "--- Phase 3: Experimentation Complete ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Define contamination values to test\n",
    "# These are illustrative; choose values that make sense for your analysis.\n",
    "# Remember the original fraud_percentage was approx 0.00172\n",
    "contamination_values_to_test = [\n",
    "    float(y_true.value_counts(normalize=True)[1]), # Baseline (actual fraud rate)\n",
    "    0.001,  # Slightly lower\n",
    "    0.002,  # Slightly higher\n",
    "    0.005   # Even higher, to see impact\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for cont_rate in contamination_values_to_test:\n",
    "    print(f\"\\nTesting Isolation Forest with contamination = {cont_rate:.4f}\")\n",
    "\n",
    "    # Re-instantiate and retrain model for each contamination value\n",
    "    iso_forest_exp = IsolationForest(\n",
    "        n_estimators=100,\n",
    "        contamination=cont_rate,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    iso_forest_exp.fit(X)\n",
    "\n",
    "    # Get predictions\n",
    "    df_temp = df.copy()\n",
    "    df_temp['anomaly_prediction'] = iso_forest_exp.predict(X)\n",
    "    df_temp['is_anomaly'] = df_temp['anomaly_prediction'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "    # Calculate metrics\n",
    "    report = classification_report(y_true, df_temp['is_anomaly'], target_names=['Legitimate', 'Fraud'], output_dict=True)\n",
    "\n",
    "    # Store relevant metrics for comparison\n",
    "    results[f\"Contamination_{cont_rate:.4f}\"] = {\n",
    "        'Precision_Fraud': report['Fraud']['precision'],\n",
    "        'Recall_Fraud': report['Fraud']['recall'],\n",
    "        'F1_Fraud': report['Fraud']['f1-score'],\n",
    "        'Num_Predicted_Anomalies': df_temp['is_anomaly'].sum(),\n",
    "    }\n",
    "\n",
    "    print(f\"Classification Report for contamination={cont_rate:.4f}:\")\n",
    "    print(classification_report(y_true, df_temp['is_anomaly'], target_names=['Legitimate', 'Fraud']))\n",
    "\n",
    "    # Optional: Display confusion matrix for each as well, or just for the best one later\n",
    "    conf_matrix_exp = confusion_matrix(y_true, df_temp['is_anomaly'])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_exp)\n",
    "\n",
    "print(\"\\n--- Contamination Experimentation Summary ---\")\n",
    "for cont_param, metrics in results.items():\n",
    "    print(f\"{cont_param}:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"  {metric_name}: {value:.4f}\")\n",
    "\n",
    "print(\"\\n--- Phase 3: Experimentation Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba7a36a",
   "metadata": {},
   "source": [
    "- For a bank, missing fraud (low recall, high FN) is extremely costly. Thus, they might prioritize a higher recall, even if it means more false positives (lower precision) that require manual review. The contamination=0.0050 scenario, despite its low precision, might be preferable if the cost of missing fraud is exceptionally high.\n",
    "- Conversely, if manual review resources are severely limited, a higher precision (like contamination=0.0010) might be chosen to reduce the burden of false alarms, accepting that some fraud will be missed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

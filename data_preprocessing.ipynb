{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98fc1680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\".\\data\\creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85d9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Time' Column\n",
    "# The 'Time' (elapsed seconds) feature is often less directly impactful than the transaction characteristics themselves.\n",
    "\n",
    "# Scale 'Amount' feature: The 'Amount' feature has a very different scale and distribution compared to the PCA-transformed 'V' features. Algorithms like Isolation Forest (which rely on partitioning data based on feature values) can be sensitive to feature scales. Standardizing 'Amount' ensures it contributes fairly to the model without disproportionately influencing the splitting process due to its larger magnitude. The 'V' features are already implicitly scaled by PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd03d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Data Preprocessing ---\n",
      "Dropped 'Time' column. New DataFrame shape: (284807, 30)\n",
      "Separated features (X) and target (y_true). X shape: (284807, 29), y_true shape: (284807,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"\\n--- Starting Data Preprocessing ---\")\n",
    "\n",
    "df_processed = df.drop('Time', axis=1)\n",
    "print(f\"Dropped 'Time' column. New DataFrame shape: {df_processed.shape}\")\n",
    "\n",
    "# 2. Separate features (X) and target (y_true)\n",
    "# The 'Class' column (0: legitimate, 1: fraud) is our ground truth.\n",
    "# For unsupervised learning, the model will not see 'y_true' during training.\n",
    "# We keep it separate solely for later evaluation of how well the unsupervised model\n",
    "# aligns with actual fraud.\n",
    "\n",
    "X = df_processed.drop('Class', axis=1)\n",
    "y_true = df_processed['Class']\n",
    "\n",
    "print(f\"Separated features (X) and target (y_true). X shape: {X.shape}, y_true shape: {y_true.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "005f787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Scale the 'Amount' feature\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X['Amount'] = scaler.fit_transform(X[['Amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5412c6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled 'Amount' feature using StandardScaler.\n",
      "First 5 rows of features (X) after preprocessing:\n",
      "         V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
      "0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
      "1  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
      "2  0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679  0.909412   \n",
      "3  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
      "4 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
      "\n",
      "        V24       V25       V26       V27       V28    Amount  \n",
      "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  0.244964  \n",
      "1 -0.339846  0.167170  0.125895 -0.008983  0.014724 -0.342475  \n",
      "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  1.160686  \n",
      "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  0.140534  \n",
      "4  0.141267 -0.206010  0.502292  0.219422  0.215153 -0.073403  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Scaled 'Amount' feature using StandardScaler.\")\n",
    "print(\"First 5 rows of features (X) after preprocessing:\")\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6466a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(r\".\\data\\preprocessed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bc548cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.to_csv(r\".\\data\\y_true.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93efce5a",
   "metadata": {},
   "source": [
    "- Created feature matrix X which the Isolation Forest model will learn from.\n",
    "- The Amount feature is now on a comparable scale to the V features, preventing it from dominating the model's decision-making solely due to its magnitude.\n",
    "- Explicitly separated y_true (the Class column) to reinforce that the model is unsupervised â€“ it trains without ever seeing these labels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
